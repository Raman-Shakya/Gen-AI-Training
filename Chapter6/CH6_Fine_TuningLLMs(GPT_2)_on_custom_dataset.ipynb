{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u61bhMXLWK8"
      },
      "source": [
        "## Fine Tuning GPT-*2*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9beLSvNcLFd_"
      },
      "source": [
        "GPT-2 is already good at generating language. But suppose you want it to:\n",
        "\n",
        "- Write poems like Nepali literature\n",
        "- Answer legal or medical questions accurately\n",
        "- Generate code comments for your Python functions\n",
        "\n",
        "Then, fine-tuning helps it learn your style or domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnp4G2NGLSxs"
      },
      "source": [
        "During fine-tuning:\n",
        "\n",
        "- You give it your data (e.g., train.txt) with examples.\n",
        "\n",
        "- It re-adjusts its weights using your data (via backpropagation).\n",
        "\n",
        "- Now itâ€™s better at doing what your data shows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnXDWtd02ub8"
      },
      "source": [
        "# Install the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwk6OoI2Ep7Z",
        "outputId": "138370c3-53c0-469c-eddb-d2417676a8bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\raman\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.7.34)\n",
            "Requirement already satisfied: requests in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.7.14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9PhAQicEyQd",
        "outputId": "42b6d946-9068-4d40-c269-7f367a014af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\raman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (4.14.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U PyPDF2\n",
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DIt3N_r2zr8"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ItYpaZD9EH7J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "import docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUnIWbFDNDSZ",
        "outputId": "6bd591a5-d88b-4165-beba-5f5392e59add"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: '/content/'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/content/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/content/'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/content/\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tUJzUv3MdQ"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RCPr_L0uJdo",
        "outputId": "e5fdc37b-8738-4f68-8e1c-32f6407084e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Static routing is a technique in computer networks where routes are manually configured by the network administrator. Unlike dynamic routing, which adapts to network changes automatically, static rout\n"
          ]
        }
      ],
      "source": [
        "with open('train.txt', 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "\n",
        "print(content[:200])\n",
        "text_data = re.sub(r'\\n+', '\\n', content).strip()  # Remove excess newline characters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPs-L20TIcK"
      },
      "source": [
        "What we will do ?\n",
        "1. Loads a GPT-2 tokenizer and model.\n",
        "2. Loads your custom training dataset.\n",
        "3. Prepares the model and training arguments.\n",
        "4. Trains the GPT-2 model on your dataset.\n",
        "5. Saves the trained model and tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LYOQhdo3XKt"
      },
      "source": [
        "# Library for the GPT2 finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MFaNgaDEVKP"
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk_14dI9EVdD"
      },
      "outputs": [],
      "source": [
        "def load_dataset(file_path, tokenizer, block_size = 64):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJcoT-aNFcKp"
      },
      "outputs": [],
      "source": [
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=mlm,\n",
        "    )\n",
        "    return data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub3THjJ_FdSw"
      },
      "outputs": [],
      "source": [
        "def train(train_file_path,model_name,\n",
        "          output_dir,\n",
        "          overwrite_output_dir,\n",
        "          per_device_train_batch_size,\n",
        "          num_train_epochs,\n",
        "          save_steps):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "  tokenizer.pad_token = tokenizer.eos_token  # fix: avoid attention_mask warning\n",
        "\n",
        "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "  data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "  model.save_pretrained(output_dir)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "          output_dir=output_dir,\n",
        "          overwrite_output_dir=overwrite_output_dir,\n",
        "          per_device_train_batch_size=per_device_train_batch_size,\n",
        "          num_train_epochs=num_train_epochs,\n",
        "      )\n",
        "\n",
        "  trainer = Trainer(\n",
        "          model=model,\n",
        "          args=training_args,\n",
        "          data_collator=data_collator,\n",
        "          train_dataset=train_dataset,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mXiWKHbFr2f"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_file_path = \"/content/train.txt\"\n",
        "model_name = 'gpt2'\n",
        "output_dir = '/content/'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 1000\n",
        "save_steps = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "WMdaTo7KF9uo",
        "outputId": "16f9c647-1886-4456-cb1e-24504e437b26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 04:52, Epoch 1000/1000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.094400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.008700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train\n",
        "train(\n",
        "    train_file_path=train_file_path,\n",
        "    model_name=model_name,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=overwrite_output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwGS1IMlGBMB"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lelq_sN4Gy5M"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOvrNQRAG2IP"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "    return tokenizer\n",
        "\n",
        "def generate_text(model_path, sequence, max_length):\n",
        "\n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample=True,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNx7gjeRieD"
      },
      "source": [
        "This model got trained on the entire text and took much longer to train, and yet it fails to give meaningful results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mTDTrpnG5Ut",
        "outputId": "9364a4f3-e713-47b6-926f-65823baa0e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Question] what is router? IPv4 uses 32-bit addresses, while IPv6 uses 128-bit addresses to accommodate the growing number of devices on the internet.\n",
            "\n",
            "Dynamic routing protocols like OSPF (Open Shortest Path First)\n"
          ]
        }
      ],
      "source": [
        "model1_path = \"/content/checkpoint-1000\"\n",
        "sequence1 = \"[Question] what is router?\"\n",
        "max_len = 50\n",
        "generate_text(model1_path, sequence1, max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxvbeKfRs35"
      },
      "source": [
        "The following model was trained on 100 questions and answers based on the original text and it trained in a few seconds (50 epochs). It gives very meaningful results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeB_1gCc5c6e",
        "outputId": "2f85661e-dd40-4cb0-e306-263263848741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Question] what faculty does hcoe provide?\n",
            "\n",
            "The HEC-10 is a dynamic updateable data transmission network that ensures reliable data transfer across interconnected networks. It improves efficiency in data transmission and enhances security by isolating segments of the network.\n",
            "\n",
            "The Transmission Control Protocol (TCP) is a connection-oriented protocol that ensures reliable data transfer across interconnected networks. It improves efficiency in data transmission across interconnected networks and enhances security by isolating segments of the network.\n",
            "\n",
            "The Transmission\n"
          ]
        }
      ],
      "source": [
        "model1_path = \"/content/checkpoint-1000\"\n",
        "sequence1 = \"[Question] what faculty does hcoe provide?\"\n",
        "max_len = 100\n",
        "generate_text(model1_path, sequence1, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6wiGek-5pBB"
      },
      "outputs": [],
      "source": [
        "model1_path = \"/content/checkpoint-1500\"\n",
        "sequence1 = \"[Question] what is the full form of hcoe?\"\n",
        "max_len = 50\n",
        "generate_text(model1_path, sequence1, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykUUb18B55MY"
      },
      "outputs": [],
      "source": [
        "model1_path = \"/content/checkpoint-1500\"\n",
        "sequence1 = \"[Question] who is the principal of himalayan college of engineering?\"\n",
        "max_len = 50\n",
        "generate_text(model1_path, sequence1, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNPrbb0Tt04Y"
      },
      "outputs": [],
      "source": [
        "!mv checkpoint-* drive/MyDrive/gen-ai-training-dataset/gpt2-finetune-for-300epoch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83M74tIpFpcj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
