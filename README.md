# Generative AI Training Program

Organized by the **AI/ML Tech Community, St. Xavier’s College**
Instructor: `Er. Sujan Sharma` (Machine Learning Engineer, Faculty)

## Program Overview

Generative AI is revolutionizing the way we approach content creation, interaction, and
automation. This 24-hour training is tailored to equip students with the technical and practical
skills needed to build real-world generative systems using state-of-the-art models and tools.

### Objectives

* Understand and implement core generative models.
* Build and deploy LLM-powered applications for text generation.
* Work with Retrieval-Augmented Generation (RAG) and intelligent AI agents.
* Strengthen your portfolio for internships, research, or further study.

### Detailed Syllabus

* *Generative AI*: Generative Models, LLMs and Agents
* *Total Duration*: 24 hours

**Prerequisites**: Basic Python programming skills, familiarity with machine learning concepts, and understanding of linear algebra and probability. Some experience with data processing and neural networks is recommended.

**Resources Required**: For onsite participation, a laptop with a charger is required. For online participation, a stable internet connection is necessary to ensure smooth participation.

1. Set up and Python for ML
   1. What is Generative AI? Historical evolution & applications
   2. Course roadmap and expectations
   3. Setting up Python, PyTorch, Hugging Face, Diffusers, LangChain
   4. Quick review: Python for ML (NumPy, Pandas, Matplotlib)

2. Review of ML Concepts
   1. Core ML Paradigms
   2. Essential Algorithms Recap
   3. Mathematical Foundations
   4.  ML in the Context of Generative AI

3.  Neural Networks and the Path to Generative Models
    1.  CNNs: convolutional layers & feature extraction
    2.  RNNs: structure and working principle
    3.  LSTMs and GRUs: solving vanishing gradients
    4.  The evolution to autoencoders, VAEs, and GANs

4.  NLP Foundations and Embeddings
    1.  Mathematical intuition: word embeddings, vector spaces & Tokenization
    2.  Contextual embeddings: Word2Vec → BERT → modern embeddings
    3.  Using Hugging Face for embedding generation
    4.  Visualizing embeddings & measuring semantic similarity

5.  Transformers and Hugging Face
    1.  Transformer architecture: attention, encoder-decoder blocks
    2.  Mathematical intuition: self-attention & positional encoding
    3.  Using Hugging Face Transformers for text generation
    4.  Generate text with GPT-2 and analyze outputs

6.  Fine-Tuning LLMs (GPT-2)
    1.  Why fine-tune?
    2.  Fine-tuning GPT-2 on a small dataset with Hugging Face Trainer
    3.  LoRA & parameter-efficient methods: making fine-tuning lightweight
    4.  Intro to prompt engineering: basic zero-shot and few-shot prompts

7.  RAG Fundamentals
    1.  What is Retrieval-Augmented Generation (RAG)? Why it’s crucial
    2.  Building a simple RAG pipeline (retriever + generator)
    3.  Vector databases: FAISS/Chroma for document retrieval
    4.  Prompt engineering for RAG: zero-shot, few-shot, chain-of-thought

8.  Building RAG Chatbots
    1.  Conversational memory: enabling multi-turn interactions
    2.  LangChain essentials: chains, retrievers, memory management
    3.  Integrating RAG into assistants: connecting retrieval with generation
    4.  Hands-on: build a PDF Q&A chatbot with LangChain

9.  AI Agents
    1.  What are AI agents? Tools, memory, and reasoning loops
    2.  Planning & decision-making in agentic systems
    3.  Building a simple AI agent with LangChain
    4.  Agent interaction with external tools/APIs

10. Ethics, Responsibility and Future of Generative AI
    1.  Ethics & Safety: bias, hallucinations, and responsible use
    2.  Privacy & IP: data protection and copyright challenges
    3.  Trust & Accountability: fairness, transparency, and reliability
    4.  Future Trends: multimodal LLMs, advanced AI agents, and next-gen GenAI

11. Capstone Project
    1.  Define problem statement & dataset
    2.  Build, discuss & improve GenAI application
    3.  A live demo

---

## Repository Folder Structure

```bash
/ Chapter1
/ Chapter2
/ ...
/ Project
  / <ProjectName>
  / ...
```
